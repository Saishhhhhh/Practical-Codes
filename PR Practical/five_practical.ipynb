{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9aa3cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 950us/step - loss: 0.2945 - accuracy: 0.9130\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 998us/step - loss: 0.1444 - accuracy: 0.9575\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 822us/step - loss: 0.1087 - accuracy: 0.9669\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 803us/step - loss: 0.0892 - accuracy: 0.9722\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 816us/step - loss: 0.0748 - accuracy: 0.9763\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the MNIST dataset (handwritten digits 0â€“9)\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Build the neural network model\n",
    "model = keras.models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"handwritten_digit_recognition_model.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f928aace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Name:- Anjali Shirke \n",
      "\n",
      "Roll no:- TEBD23207 \n",
      "\n",
      "313/313 - 0s - loss: 0.0714 - accuracy: 0.9782\n",
      "\n",
      "Test accuracy: 0.9782000184059143\n",
      "Predicted digit: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n\\n\")\n",
    "print(\"Name:- Anjali Shirke \\n\")\n",
    "print(\"Roll no:- TEBD23207 \\n\")\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"\\nTest accuracy:\", test_acc)\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(\"handwritten_digit_recognition_model.h5\")\n",
    "\n",
    "# Load an example image (replace with your own image path)\n",
    "image_path = \"example_digit.png\"\n",
    "image = tf.keras.preprocessing.image.load_img(\n",
    "    image_path,\n",
    "    color_mode=\"grayscale\",\n",
    "    target_size=(28, 28)\n",
    ")\n",
    "\n",
    "# Convert image to array and normalize\n",
    "input_data = tf.keras.preprocessing.image.img_to_array(image)\n",
    "input_data = input_data / 255.0\n",
    "\n",
    "# Make a prediction\n",
    "prediction = model.predict(np.array([input_data]))\n",
    "predicted_digit = np.argmax(prediction)\n",
    "\n",
    "# Show the image and prediction\n",
    "print(\"Predicted digit:\", predicted_digit)\n",
    "plt.imshow(input_data.reshape(28, 28), cmap=\"binary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e7d28b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "booksenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
